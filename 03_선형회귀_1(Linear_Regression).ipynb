{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03.선형회귀_1(Linear Regression).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qZ3JS9c8kLtF",
        "dxRUt3PLkRoK",
        "dx0l7MbckV2G",
        "yoaTnvITlcOr",
        "QvJJ5_Cbl6Hy"
      ],
      "authorship_tag": "ABX9TyMkePYieJajAMfU/V3kJr0y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehho34/PyTorch/blob/main/03_%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80_1(Linear_Regression).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**03.선형회귀(Linear Regression)**"
      ],
      "metadata": {
        "id": "Mkds3YxiWUvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**01-선형 회귀**"
      ],
      "metadata": {
        "id": "SHk5dwQxWVIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**데이터에 대한 이해(Data Definition)**"
      ],
      "metadata": {
        "id": "mKZYD0iwW9Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "-예측을 위해 사용하는 데이터 == 훈련 데이터셋(training dataset)\n",
        "-학습이 끝난 후에 이 모델이 얼마나 잘 작동하는지 판별 == 테스트 데이터셋(test dataset)\n",
        "\n",
        "-훈련 데이터셋의 구성\n",
        "  -모델을 학습시키기 위한 데이터는 파이토치의 텐서 형태여야 함!\n",
        "  -입력과 출력은 서로 다른 텐서에 저장해야 함!(입력은 x, 출력은 y)<-보편적으로~\n",
        "  EX) 공부시간과 점수(아래 사진 참고)\n",
        "  x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "  y_train = torch.FloatTensor([[2],[4],[6]])\n",
        "\n",
        "-가설(Hypothesis) 수립\n",
        "  -머신 러닝에서 식을 세울 때 이 식을 가설이라고 함\n",
        "\n",
        "-선형 회귀\n",
        " -이 가설은 널리 알려져 있으니까 고민 불필요\n",
        " -선형 회귀란? : 학습 데이터와 가장 잘 맞는 하나의 직선을 찾는 일\n",
        "                 일반적으로 이런 식     y = Wx + b \n",
        "                                     H(x) = Wx + b 을 가진다 (가설의 H를 따서 y대신 쓴 것뿐임)\n",
        "                                     -여기서 x와 곱해지는 W를 가중치(Weight)라고 하며, b를 편향(bias)라고 함\n",
        "                                     -W와 b는 중학교 수학 과정 직선의 방정식에서 기울기와 y절편에 해당\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "code",
        "id": "eN8hdVkdXIKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "-비용 함수(Cost Function)에 대한 이해\n",
        "=손실 함수(loss function)=오차 함수(error function)=목적 함수(objective function)\n",
        "★ 특히 비용 함수, 손실 함수 기억해두기 ★\n",
        "\n",
        "-(실제값-예측값)의 제곱을 다 더하고 데이터의 개수로 나눈 것! -> 평균 제곱 오차(Mean Squared Error, MSE)\n",
        "-Cost(W,b)를 최소로 만드는 W와 b를 구하면 훈련 데이터를 가장 잘 나타내는 직선을 구할 수 있다!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "81IXOAMda8-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "-옵티마이저 - 경사 하강법(Gradient Descent)\n",
        "-기울기가 지나치게 크면 실제값과 예측값의 오차가 커기고 기울기가 지나치게 작아도 마찬가지\n",
        "-사실 b 또한 위와 같음\n",
        "\n",
        "-cost가 최소화 되는 지점은 접선의 기울기가 0이 되는 지점 = 미분값이 0이 되는 지점\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "M8-Xuu0YboaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**파이토치로 선형 회귀 구현하기**"
      ],
      "metadata": {
        "id": "dMoThFVEj_iV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**1.기본 셋팅**"
      ],
      "metadata": {
        "id": "qZ3JS9c8kLtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "vF3kS55wgg2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#현재 실습하고 있는 코드를 다시 실행해도 다음에도 같은 결과가 나올 수 있게 랜덤 시들들 줄이기\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlmFUt5ygsGB",
        "outputId": "ebf4bddc-40e6-4a7f-a3ce-c962483a5075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f17ff448c90>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**2.변수 선언**"
      ],
      "metadata": {
        "id": "dxRUt3PLkRoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])"
      ],
      "metadata": {
        "id": "JLlI6ZiHjMZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "y7pHbrzugsZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e266dec3-298e-4be6-9669-00045473a03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "Guo_3qzBgsms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59490b3-8999-48c4-f9ef-acbd10f6f250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.],\n",
            "        [4.],\n",
            "        [6.]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**3.가중치와 편향의 기초화**"
      ],
      "metadata": {
        "id": "dx0l7MbckV2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시함.\n",
        "W = torch.zeros(1, requires_grad=True)  #requires_grad=True <- '이 변수는 학습을 통해 계속 값이 변경되는 변수임'\n",
        "#가중치 W를 출력\n",
        "print(W)"
      ],
      "metadata": {
        "id": "pNA-jF_9gsvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3692303-682a-42d6-e738-9734aed48ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#편향 b를 0으로 초기화하고 얘도 학습을 통해 값이 변경되는 변수임을 명시하자!\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8v9GGCCk0DI",
        "outputId": "9a73e160-2a69-4c4b-a930-1bad3201138f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#W와 b의 값이 모두 0이기 때문에 현재 이 직선의 방정식은 y = 0 X x + 0 --> x에 어떤 수가 들어가더라도 가설은 0을 예측할 것임!"
      ],
      "metadata": {
        "id": "Wgvmhmq5lEi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**4.가설 세우기**\n",
        "H(x) = Wx + b"
      ],
      "metadata": {
        "id": "yoaTnvITlcOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis = x_train * W + b\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNFlSe8vlEkb",
        "outputId": "7717cfe9-9c1c-4974-c9d5-f382b6d95f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**5.비용 함수 선언하기**"
      ],
      "metadata": {
        "id": "QvJJ5_Cbl6Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#평균 구하기(torch.mean 사용)\n",
        "cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWHZPaRJlEoo",
        "outputId": "dc2f824c-45ae-43df-a6bf-292405667cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**6.경사 하강법 구현하기**\n"
      ],
      "metadata": {
        "id": "cn3I18ZW4_Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD([W,b],lr=0.01)  #SDG(경사 하강법의 일종), lr(learning rate, 학습률)"
      ],
      "metadata": {
        "id": "tGvBeL3_48jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#미분을 통해 얻은 기울기를 0으로 초기화(기울기를 초기화해야지 새로운 가중치 편향에 대해서 새로운 기울기를 구할 수 있다.)\n",
        "#gradient를 0으로 초기화\n",
        "optimizer.zero_grad()\n",
        "#비용 함수를 미분하여 gradient 계산 \n",
        "cost.backward() #이 함수를 호출하면 인수로 들어갔던 W와 b에서 리턴되는 변수들의 기울기에 학습률(learning rate) 0.01을 곱하여 빼줌으로서 업데이트"
      ],
      "metadata": {
        "id": "hFd9WLgz48l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**7.전체 코드**"
      ],
      "metadata": {
        "id": "-I86jv4MZ6WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터\n",
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])\n",
        "\n",
        "#모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "#optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr=0.01)\n",
        "\n",
        "nb_epochs = 1999 #원하는만큼 경사 하강법을 반복\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  #H(x) 계산\n",
        "  hypothesis = x_train * W + b\n",
        "\n",
        "  #cost 계산\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "  #cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  #100번마다 로그 출력\n",
        "  if epoch % 100 ==0:\n",
        "    print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        ",     ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_0lZqJEZNrf",
        "outputId": "c83f8969-c645-456c-a7cd-15211334c197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1999 W: 0.187, b: 0.080 Cost: 18.666666\n",
            "Epoch  100/1999 W: 1.746, b: 0.578 Cost: 0.048171\n",
            "Epoch  200/1999 W: 1.800, b: 0.454 Cost: 0.029767\n",
            "Epoch  300/1999 W: 1.843, b: 0.357 Cost: 0.018394\n",
            "Epoch  400/1999 W: 1.876, b: 0.281 Cost: 0.011366\n",
            "Epoch  500/1999 W: 1.903, b: 0.221 Cost: 0.007024\n",
            "Epoch  600/1999 W: 1.924, b: 0.174 Cost: 0.004340\n",
            "Epoch  700/1999 W: 1.940, b: 0.136 Cost: 0.002682\n",
            "Epoch  800/1999 W: 1.953, b: 0.107 Cost: 0.001657\n",
            "Epoch  900/1999 W: 1.963, b: 0.084 Cost: 0.001024\n",
            "Epoch 1000/1999 W: 1.971, b: 0.066 Cost: 0.000633\n",
            "Epoch 1100/1999 W: 1.977, b: 0.052 Cost: 0.000391\n",
            "Epoch 1200/1999 W: 1.982, b: 0.041 Cost: 0.000242\n",
            "Epoch 1300/1999 W: 1.986, b: 0.032 Cost: 0.000149\n",
            "Epoch 1400/1999 W: 1.989, b: 0.025 Cost: 0.000092\n",
            "Epoch 1500/1999 W: 1.991, b: 0.020 Cost: 0.000057\n",
            "Epoch 1600/1999 W: 1.993, b: 0.016 Cost: 0.000035\n",
            "Epoch 1700/1999 W: 1.995, b: 0.012 Cost: 0.000022\n",
            "Epoch 1800/1999 W: 1.996, b: 0.010 Cost: 0.000013\n",
            "Epoch 1900/1999 W: 1.997, b: 0.008 Cost: 0.000008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**optimizer.zero_grad()가 필요한 이유**"
      ],
      "metadata": {
        "id": "Ceysy0Fecpua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#파이토치는 미분을 통해 얻은 기울기를 이전에 계산된 기울기 값에 누적시키는 특징이 있습니다."
      ],
      "metadata": {
        "id": "IoRpis57ZN2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  z =2*w\n",
        "\n",
        "  z.backward()\n",
        "  print('수식을 w로 미분한 값 : {}'.format(w.grad))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUCk_UGvc68K",
        "outputId": "762a6318-cc74-4027-859f-28cffd59afcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수식을 w로 미분한 값 : 2.0\n",
            "수식을 w로 미분한 값 : 4.0\n",
            "수식을 w로 미분한 값 : 6.0\n",
            "수식을 w로 미분한 값 : 8.0\n",
            "수식을 w로 미분한 값 : 10.0\n",
            "수식을 w로 미분한 값 : 12.0\n",
            "수식을 w로 미분한 값 : 14.0\n",
            "수식을 w로 미분한 값 : 16.0\n",
            "수식을 w로 미분한 값 : 18.0\n",
            "수식을 w로 미분한 값 : 20.0\n",
            "수식을 w로 미분한 값 : 22.0\n",
            "수식을 w로 미분한 값 : 24.0\n",
            "수식을 w로 미분한 값 : 26.0\n",
            "수식을 w로 미분한 값 : 28.0\n",
            "수식을 w로 미분한 값 : 30.0\n",
            "수식을 w로 미분한 값 : 32.0\n",
            "수식을 w로 미분한 값 : 34.0\n",
            "수식을 w로 미분한 값 : 36.0\n",
            "수식을 w로 미분한 값 : 38.0\n",
            "수식을 w로 미분한 값 : 40.0\n",
            "수식을 w로 미분한 값 : 42.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**torch.manual_seed()를 하는 이유**"
      ],
      "metadata": {
        "id": "HGiWzgd2ix0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.manual_seed()를 사용한 프로그램의 결과는 다른 컴퓨터에서 실행시켜도 동일한 결과를 낸다.\n",
        "#torch.manual_seed()는 난수 발생 순서와 값을 동일하게 보장해주는 특징을 갖고 있기 때문이다!"
      ],
      "metadata": {
        "id": "Ah3jrsJgiz_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "zTEYhoPyjMaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(3) #랜덤시드가 3\n",
        "print('랜덤 시드가 3일 때')\n",
        "for i in range(1,3):\n",
        "  print(torch.rand(1))\n",
        "#랜덤시드가 3일 때 난수 2개를 발생시켰더니 0.0043과 0.1056이 나옴  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20Za5EYdjM65",
        "outputId": "a3edfb1d-2b1b-4628-b543-1a30c547dfb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시드가 3일 때\n",
            "tensor([0.0043])\n",
            "tensor([0.1056])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(5)\n",
        "print('랜덤 시드가 5일 때')\n",
        "for i in range(1,3):\n",
        "  print(torch.rand(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj7DhGPNkFBY",
        "outputId": "68b68b0a-0053-4c52-8961-672ce95523a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시드가 5일 때\n",
            "tensor([0.8303])\n",
            "tensor([0.1261])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#다시 랜덤 시드값을 처음에 한 것처럼 3으로 돌려보자! 그럼 어떻게 될까?\n",
        "torch.manual_seed(3)\n",
        "print('랜덤 시드가 3일 때')\n",
        "for i in range(1,3):\n",
        "  print(torch.rand(1))\n",
        "  #동일한 값 도출"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCxlTikNkbcL",
        "outputId": "e0df844e-f908-4f2a-f06a-91cf4bd8ca83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시드가 3일 때\n",
            "tensor([0.0043])\n",
            "tensor([0.1056])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tersor에는 requires_grab라는 속성이 있는데, requires+grab=True로 설정하면 자동 미분 기능이 적용된다.\n",
        "#이렇게 설정된 텐서에서 연산을 하면 계산 그래프가 생성됨. backward 함수를 호출하면 그래프로부터 자동으로 미분이 계산된다! "
      ],
      "metadata": {
        "id": "RTxIadTnlXf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**02.자동 미분(Autograd)**"
      ],
      "metadata": {
        "id": "HA4fYNdom6lF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.경사 하강법 리뷰"
      ],
      "metadata": {
        "id": "-oLF-jErm_7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#경사 하강법 : 비용함수를 미분 -> 이함수의 기울기를 구하여 비용이 최소화 되는 방향을 찾아내는 알고리즘\n",
        "#비용함수=손실함수=오차함수\n",
        "#비용(=손실=오차)을 최소화 되는 방향"
      ],
      "metadata": {
        "id": "svrhWrLwm6F6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**2.자동 미분(Autograb) 실습하기**"
      ],
      "metadata": {
        "id": "kxlJ2t-Fnsb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모델이 복잡해지면 직접 코딩하기 까다롭잖아? 그러니까 자동미분으로 미분 계산을 자동화 하자~\n",
        "import torch"
      ],
      "metadata": {
        "id": "e8_B2oB4nsMe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#값이 2인 임의의 스칼라 텐서 w를 생성\n",
        "w = torch.tensor(2.0, requires_grad=True) #'requires_grad=True'==이 텐서에 대한 기울기를 저장하겠다!"
      ],
      "metadata": {
        "id": "kn8cl9Twn20f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#수식 정의\n",
        "y = w**2\n",
        "z = 2*y +5"
      ],
      "metadata": {
        "id": "Fz8EsBQZn3Oy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#수식을 w에 대해서 미분하기!\n",
        "z.backward()  #.backward()를 호출하면 해당 수식의 w에 대한 기울기를 계산함"
      ],
      "metadata": {
        "id": "ucHGFIqYn3Ve"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#w.grad 출력\n",
        "print('수식을 w로 미분한 값 : {}'.format(w.grad))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyH4Uwhfn3Zn",
        "outputId": "5dc54c3a-4cf0-461f-b628-b345a9ff13e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수식을 w로 미분한 값 : 8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**03. 다중 선형 회귀(Multivariable Linear regression)**\n",
        "#####*x가* 1개인 선형 회귀를 단순 선형회귀라고 함. 다중 선형 회귀는 다수의 x로부터 y를 예측하는 것!"
      ],
      "metadata": {
        "id": "Ozybwt69p4dO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**2.파이토치로 구현하기**"
      ],
      "metadata": {
        "id": "7C375bhhqAyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "7tCVEsE2n3dC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.maanual_seed(1) #랜덤시드 고정"
      ],
      "metadata": {
        "id": "HcfQbZr3n3f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#H(x) = w1x1 + w2x2 +w3x3 + b\n",
        "#이번 데이터는 단순 선형 회귀와 달리 x의 개수가 3개!\n",
        "# 훈련 데이터(x가 3개 선언)\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "vVSDGzCcx9Qx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 w와 편향 b 선언(x가 3개니까 가중치 w도 3개 선언)\n",
        "w1 = torch.zeros(1, requires_grad=True)\n",
        "w2 = torch.zeros(1, requires_grad=True)\n",
        "w3 = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)"
      ],
      "metadata": {
        "id": "11GjcQcyx9XH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#가설, 비용함수, 옵티마이저 선언\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 1000 #경사 하강법 1000회 반복\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b  #가설을 서너\n",
        "    # ▲가설을 선언하는 이부분도 x_train의 개수만큼 w와 곱해주도록 작성!\n",
        "    \n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX3AvlHmx9cs",
        "outputId": "42c3ccdb-8c41-4813-a39b-3c196b9007e6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
            "Epoch  100/1000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost: 1.563628\n",
            "Epoch  200/1000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost: 1.497595\n",
            "Epoch  300/1000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost: 1.435044\n",
            "Epoch  400/1000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost: 1.375726\n",
            "Epoch  500/1000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost: 1.319507\n",
            "Epoch  600/1000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost: 1.266222\n",
            "Epoch  700/1000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost: 1.215703\n",
            "Epoch  800/1000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost: 1.167810\n",
            "Epoch  900/1000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost: 1.122429\n",
            "Epoch 1000/1000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**3.벡터와 행렬 연산으로 바꾸기**\n",
        "#####위의 코드 같은 경우에는 x가 3개니까 일일히 선언하는 게 가능! 근데 x가 1000개라면..? -> 너무 비효율적!\n",
        "#####이걸 해결하기 위해서 -> 행렬 곱셈 연산(벡터의 내적=Odt Product)을 사용하자!"
      ],
      "metadata": {
        "id": "xAvFsDgjd-7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**벡터 연산으로 이해하기**"
      ],
      "metadata": {
        "id": "_eg6qKoxele4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "H(X) = w1x1 + w2x2 + w3x3\n",
        "두 벡터의 내적으로 표현하면 -> H(X) = XW\n",
        "'''"
      ],
      "metadata": {
        "id": "QvEp2Y0Ax9hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**행렬 연산으로 이해하기**\n",
        "#####샘플 (sample) : 전체 훈련 데이터의 개수를 셀 수 있는 1개의 단위\n",
        "#####특성(feature) : 각 샘플에서 y를 결정하게 하는 각각의 독립 변수 x\n",
        "#####독립변수 x들의 수 = 샘플의 수 x 특성의 수"
      ],
      "metadata": {
        "id": "VXhkPVCHfO9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**행렬 연산을 고려하여 파이토치로 구현하기**"
      ],
      "metadata": {
        "id": "FTROPA1Fgrkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#행렬 연산을 고려하여 파이토치로 재구현 <- 훈련 데이터도 행렬로 선언해주어야 함\n",
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  80], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
      ],
      "metadata": {
        "id": "eHzKyRH2fLxR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3eeCN1CfL4f",
        "outputId": "16f6af38-f56b-4fb5-9692-8df9253ab482"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3])\n",
            "torch.Size([5, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#가중치와 편향 선언\n",
        "W = torch.zeros((3,1), requires_grad=True) \n",
        "#행렬의 곱셉이 성립되려면 좌측에 있는 행렬과 우측에 있는 행렬 크기가 같아아 햠\n",
        "#X_train(5X3), W벡터의 크기(3X1)이므로 행렬곱 가능!\n",
        "\n",
        "b = torch.zeros(1, requires_grad=True)"
      ],
      "metadata": {
        "id": "cTHW8NyRfMAg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#가설 선언\n",
        "hypothesis = x_train.matmul(W) + b"
      ],
      "metadata": {
        "id": "zbeBvzrEfMKl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#전체 코드\n",
        "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  80], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
        "\n",
        "# 모델 초기화\n",
        "W = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    # 편향 b는 브로드 캐스팅되어 각 샘플에 더해집니다.\n",
        "    hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4ADDFKpiDn9",
        "outputId": "9dcd9ee3-68fa-4156-e497-f3d8ae5434f9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch    1/20 hypothesis: tensor([66.7178, 80.1701, 76.1025, 86.0194, 61.1565]) Cost: 9537.694336\n",
            "Epoch    2/20 hypothesis: tensor([104.5421, 125.6208, 119.2478, 134.7862,  95.8280]) Cost: 3069.590088\n",
            "Epoch    3/20 hypothesis: tensor([125.9858, 151.3882, 143.7087, 162.4333, 115.4844]) Cost: 990.670288\n",
            "Epoch    4/20 hypothesis: tensor([138.1429, 165.9963, 157.5768, 178.1071, 126.6283]) Cost: 322.481873\n",
            "Epoch    5/20 hypothesis: tensor([145.0350, 174.2780, 165.4395, 186.9928, 132.9461]) Cost: 107.717064\n",
            "Epoch    6/20 hypothesis: tensor([148.9423, 178.9730, 169.8976, 192.0301, 136.5279]) Cost: 38.687496\n",
            "Epoch    7/20 hypothesis: tensor([151.1574, 181.6346, 172.4254, 194.8856, 138.5585]) Cost: 16.499043\n",
            "Epoch    8/20 hypothesis: tensor([152.4131, 183.1435, 173.8590, 196.5043, 139.7097]) Cost: 9.365656\n",
            "Epoch    9/20 hypothesis: tensor([153.1250, 183.9988, 174.6723, 197.4217, 140.3625]) Cost: 7.071114\n",
            "Epoch   10/20 hypothesis: tensor([153.5285, 184.4835, 175.1338, 197.9415, 140.7325]) Cost: 6.331847\n",
            "Epoch   11/20 hypothesis: tensor([153.7572, 184.7582, 175.3958, 198.2360, 140.9424]) Cost: 6.092532\n",
            "Epoch   12/20 hypothesis: tensor([153.8868, 184.9138, 175.5449, 198.4026, 141.0613]) Cost: 6.013817\n",
            "Epoch   13/20 hypothesis: tensor([153.9602, 185.0019, 175.6299, 198.4969, 141.1288]) Cost: 5.986785\n",
            "Epoch   14/20 hypothesis: tensor([154.0017, 185.0517, 175.6785, 198.5500, 141.1671]) Cost: 5.976325\n",
            "Epoch   15/20 hypothesis: tensor([154.0252, 185.0798, 175.7065, 198.5800, 141.1888]) Cost: 5.971208\n",
            "Epoch   16/20 hypothesis: tensor([154.0385, 185.0956, 175.7229, 198.5966, 141.2012]) Cost: 5.967835\n",
            "Epoch   17/20 hypothesis: tensor([154.0459, 185.1045, 175.7326, 198.6059, 141.2082]) Cost: 5.964969\n",
            "Epoch   18/20 hypothesis: tensor([154.0501, 185.1094, 175.7386, 198.6108, 141.2122]) Cost: 5.962291\n",
            "Epoch   19/20 hypothesis: tensor([154.0524, 185.1120, 175.7424, 198.6134, 141.2145]) Cost: 5.959664\n",
            "Epoch   20/20 hypothesis: tensor([154.0536, 185.1134, 175.7451, 198.6145, 141.2158]) Cost: 5.957089\n"
          ]
        }
      ]
    }
  ]
}