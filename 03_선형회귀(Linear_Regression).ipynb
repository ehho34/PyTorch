{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03.선형회귀(Linear Regression).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mKZYD0iwW9Iv",
        "qZ3JS9c8kLtF",
        "dxRUt3PLkRoK",
        "dx0l7MbckV2G",
        "yoaTnvITlcOr",
        "QvJJ5_Cbl6Hy"
      ],
      "authorship_tag": "ABX9TyMucBk4R0noXC6sMBCm09r8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehho34/PyTorch/blob/main/03_%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80(Linear_Regression).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**03.선형회귀(Linear Regression)**"
      ],
      "metadata": {
        "id": "Mkds3YxiWUvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**01-선형 회귀**"
      ],
      "metadata": {
        "id": "SHk5dwQxWVIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**데이터에 대한 이해(Data Definition)**"
      ],
      "metadata": {
        "id": "mKZYD0iwW9Iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "-예측을 위해 사용하는 데이터 == 훈련 데이터셋(training dataset)\n",
        "-학습이 끝난 후에 이 모델이 얼마나 잘 작동하는지 판별 == 테스트 데이터셋(test dataset)\n",
        "\n",
        "-훈련 데이터셋의 구성\n",
        "  -모델을 학습시키기 위한 데이터는 파이토치의 텐서 형태여야 함!\n",
        "  -입력과 출력은 서로 다른 텐서에 저장해야 함!(입력은 x, 출력은 y)<-보편적으로~\n",
        "  EX) 공부시간과 점수(아래 사진 참고)\n",
        "  x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "  y_train = torch.FloatTensor([[2],[4],[6]])\n",
        "\n",
        "-가설(Hypothesis) 수립\n",
        "  -머신 러닝에서 식을 세울 때 이 식을 가설이라고 함\n",
        "\n",
        "-선형 회귀\n",
        " -이 가설은 널리 알려져 있으니까 고민 불필요\n",
        " -선형 회귀란? : 학습 데이터와 가장 잘 맞는 하나의 직선을 찾는 일\n",
        "                 일반적으로 이런 식     y = Wx + b \n",
        "                                     H(x) = Wx + b 을 가진다 (가설의 H를 따서 y대신 쓴 것뿐임)\n",
        "                                     -여기서 x와 곱해지는 W를 가중치(Weight)라고 하며, b를 편향(bias)라고 함\n",
        "                                     -W와 b는 중학교 수학 과정 직선의 방정식에서 기울기와 y절편에 해당\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "code",
        "id": "eN8hdVkdXIKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf5a678-bf80-444d-a139-3d9ca86a652f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n-예측을 위해 사용하는 데이터 == 훈련 데이터셋(training dataset)\\n-학습이 끝난 후에 이 모델이 얼마나 잘 작동하는지 판별 == 테스트 데이터셋(test dataset)\\n\\n-훈련 데이터셋의 구성\\n  -모델을 학습시키기 위한 데이터는 파이토치의 텐서 형태여야 함!\\n  -입력과 출력은 서로 다른 텐서에 저장해야 함!(입력은 x, 출력은 y)<-보편적으로~\\n  EX) 공부시간과 점수(아래 사진 참고)\\n  x_train = torch.FloatTensor([[1],[2],[3]])\\n  y_train = torch.FloatTensor([[2],[4],[6]])\\n\\n-가설(Hypothesis) 수립\\n  -머신 러닝에서 식을 세울 때 이 식을 가설이라고 함\\n\\n-선형 회귀\\n -이 가설은 널리 알려져 있으니까 고민 불필요\\n -선형 회귀란? : 학습 데이터와 가장 잘 맞는 하나의 직선을 찾는 일\\n                 일반적으로 이런 식     y = Wx + b \\n                                     H(x) = Wx + b 을 가진다 (가설의 H를 따서 y대신 쓴 것뿐임)\\n                                     -여기서 x와 곱해지는 W를 가중치(Weight)라고 하며, b를 편향(bias)라고 함\\n                                     -W와 b는 중학교 수학 과정 직선의 방정식에서 기울기와 y절편에 해당\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "-비용 함수(Cost Function)에 대한 이해\n",
        "=손실 함수(loss function)=오차 함수(error function)=목적 함수(objective function)\n",
        "★ 특히 비용 함수, 손실 함수 기억해두기 ★\n",
        "\n",
        "-(실제값-예측값)의 제곱을 다 더하고 데이터의 개수로 나눈 것! -> 평균 제곱 오차(Mean Squared Error, MSE)\n",
        "-Cost(W,b)를 최소로 만드는 W와 b를 구하면 훈련 데이터를 가장 잘 나타내는 직선을 구할 수 있다!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "81IXOAMda8-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5de01d-7a5e-4376-ecc4-2c2cfc1aae23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n-비용 함수(Cost Function)에 대한 이해\\n=손실 함수(loss function)=오차 함수(error function)=목적 함수(objective function)\\n★ 특히 비용 함수, 손실 함수 기억해두기 ★\\n\\n-(실제값-예측값)의 제곱을 다 더하고 데이터의 개수로 나눈 것! -> 평균 제곱 오차(Mean Squared Error, MSE)\\n-Cost(W,b)를 최소로 만드는 W와 b를 구하면 훈련 데이터를 가장 잘 나타내는 직선을 구할 수 있다!\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "-옵티마이저 - 경사 하강법(Gradient Descent)\n",
        "-기울기가 지나치게 크면 실제값과 예측값의 오차가 커기고 기울기가 지나치게 작아도 마찬가지\n",
        "-사실 b 또한 위와 같음\n",
        "\n",
        "-cost가 최소화 되는 지점은 접선의 기울기가 0이 되는 지점 = 미분값이 0이 되는 지점\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "M8-Xuu0YboaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07c2e2b-8aa9-47ee-9987-2eab6ecd2745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n-옵티마이저 - 경사 하강법(Gradient Descent)\\n-기울기가 지나치게 크면 실제값과 예측값의 오차가 커기고 기울기가 지나치게 작아도 마찬가지\\n-사실 b 또한 위와 같음\\n\\n-cost가 최소화 되는 지점은 접선의 기울기가 0이 되는 지점 = 미분값이 0이 되는 지점\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**파이토치로 선형 회귀 구현하기**"
      ],
      "metadata": {
        "id": "dMoThFVEj_iV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**1.기본 셋팅**"
      ],
      "metadata": {
        "id": "qZ3JS9c8kLtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "vF3kS55wgg2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#현재 실습하고 있는 코드를 다시 실행해도 다음에도 같은 결과가 나올 수 있게 랜덤 시들들 줄이기\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlmFUt5ygsGB",
        "outputId": "ebf4bddc-40e6-4a7f-a3ce-c962483a5075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f17ff448c90>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**2.변수 선언**"
      ],
      "metadata": {
        "id": "dxRUt3PLkRoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])"
      ],
      "metadata": {
        "id": "JLlI6ZiHjMZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "y7pHbrzugsZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e266dec3-298e-4be6-9669-00045473a03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "Guo_3qzBgsms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59490b3-8999-48c4-f9ef-acbd10f6f250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.],\n",
            "        [4.],\n",
            "        [6.]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**3.가중치와 편향의 기초화**"
      ],
      "metadata": {
        "id": "dx0l7MbckV2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시함.\n",
        "W = torch.zeros(1, requires_grad=True)  #requires_grad=True <- '이 변수는 학습을 통해 계속 값이 변경되는 변수임'\n",
        "#가중치 W를 출력\n",
        "print(W)"
      ],
      "metadata": {
        "id": "pNA-jF_9gsvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3692303-682a-42d6-e738-9734aed48ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#편향 b를 0으로 초기화하고 얘도 학습을 통해 값이 변경되는 변수임을 명시하자!\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8v9GGCCk0DI",
        "outputId": "9a73e160-2a69-4c4b-a930-1bad3201138f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#W와 b의 값이 모두 0이기 때문에 현재 이 직선의 방정식은 y = 0 X x + 0 --> x에 어떤 수가 들어가더라도 가설은 0을 예측할 것임!"
      ],
      "metadata": {
        "id": "Wgvmhmq5lEi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**4.가설 세우기**\n",
        "H(x) = Wx + b"
      ],
      "metadata": {
        "id": "yoaTnvITlcOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis = x_train * W + b\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNFlSe8vlEkb",
        "outputId": "7717cfe9-9c1c-4974-c9d5-f382b6d95f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**5.비용 함수 선언하기**"
      ],
      "metadata": {
        "id": "QvJJ5_Cbl6Hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#평균 구하기(torch.mean 사용)\n",
        "cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWHZPaRJlEoo",
        "outputId": "dc2f824c-45ae-43df-a6bf-292405667cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**6.경사 하강법 구현하기**\n"
      ],
      "metadata": {
        "id": "cn3I18ZW4_Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD([W,b],lr=0.01)  #SDG(경사 하강법의 일종), lr(learning rate, 학습률)"
      ],
      "metadata": {
        "id": "tGvBeL3_48jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#미분을 통해 얻은 기울기를 0으로 초기화(기울기를 초기화해야지 새로운 가중치 편향에 대해서 새로운 기울기를 구할 수 있다.)\n",
        "#gradient를 0으로 초기화\n",
        "optimizer.zero_grad()\n",
        "#비용 함수를 미분하여 gradient 계산 \n",
        "cost.backward() #이 함수를 호출하면 인수로 들어갔던 W와 b에서 리턴되는 변수들의 기울기에 학습률(learning rate) 0.01을 곱하여 빼줌으로서 업데이트"
      ],
      "metadata": {
        "id": "hFd9WLgz48l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**7.전체 코드**"
      ],
      "metadata": {
        "id": "-I86jv4MZ6WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터\n",
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])\n",
        "\n",
        "#모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "#optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr=0.01)\n",
        "\n",
        "nb_epochs = 1999 #원하는만큼 경사 하강법을 반복\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  #H(x) 계산\n",
        "  hypothesis = x_train * W + b\n",
        "\n",
        "  #cost 계산\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "  #cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  #100번마다 로그 출력\n",
        "  if epoch % 100 ==0:\n",
        "    print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        ",     ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_0lZqJEZNrf",
        "outputId": "c83f8969-c645-456c-a7cd-15211334c197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1999 W: 0.187, b: 0.080 Cost: 18.666666\n",
            "Epoch  100/1999 W: 1.746, b: 0.578 Cost: 0.048171\n",
            "Epoch  200/1999 W: 1.800, b: 0.454 Cost: 0.029767\n",
            "Epoch  300/1999 W: 1.843, b: 0.357 Cost: 0.018394\n",
            "Epoch  400/1999 W: 1.876, b: 0.281 Cost: 0.011366\n",
            "Epoch  500/1999 W: 1.903, b: 0.221 Cost: 0.007024\n",
            "Epoch  600/1999 W: 1.924, b: 0.174 Cost: 0.004340\n",
            "Epoch  700/1999 W: 1.940, b: 0.136 Cost: 0.002682\n",
            "Epoch  800/1999 W: 1.953, b: 0.107 Cost: 0.001657\n",
            "Epoch  900/1999 W: 1.963, b: 0.084 Cost: 0.001024\n",
            "Epoch 1000/1999 W: 1.971, b: 0.066 Cost: 0.000633\n",
            "Epoch 1100/1999 W: 1.977, b: 0.052 Cost: 0.000391\n",
            "Epoch 1200/1999 W: 1.982, b: 0.041 Cost: 0.000242\n",
            "Epoch 1300/1999 W: 1.986, b: 0.032 Cost: 0.000149\n",
            "Epoch 1400/1999 W: 1.989, b: 0.025 Cost: 0.000092\n",
            "Epoch 1500/1999 W: 1.991, b: 0.020 Cost: 0.000057\n",
            "Epoch 1600/1999 W: 1.993, b: 0.016 Cost: 0.000035\n",
            "Epoch 1700/1999 W: 1.995, b: 0.012 Cost: 0.000022\n",
            "Epoch 1800/1999 W: 1.996, b: 0.010 Cost: 0.000013\n",
            "Epoch 1900/1999 W: 1.997, b: 0.008 Cost: 0.000008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**optimizer.zero_grad()가 필요한 이유**"
      ],
      "metadata": {
        "id": "Ceysy0Fecpua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#파이토치는 미분을 통해 얻은 기울기를 이전에 계산된 기울기 값에 누적시키는 특징이 있습니다."
      ],
      "metadata": {
        "id": "IoRpis57ZN2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  z =2*w\n",
        "\n",
        "  z.backward()\n",
        "  print('수식을 w로 미분한 값 : {}'.format(w.grad))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUCk_UGvc68K",
        "outputId": "762a6318-cc74-4027-859f-28cffd59afcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수식을 w로 미분한 값 : 2.0\n",
            "수식을 w로 미분한 값 : 4.0\n",
            "수식을 w로 미분한 값 : 6.0\n",
            "수식을 w로 미분한 값 : 8.0\n",
            "수식을 w로 미분한 값 : 10.0\n",
            "수식을 w로 미분한 값 : 12.0\n",
            "수식을 w로 미분한 값 : 14.0\n",
            "수식을 w로 미분한 값 : 16.0\n",
            "수식을 w로 미분한 값 : 18.0\n",
            "수식을 w로 미분한 값 : 20.0\n",
            "수식을 w로 미분한 값 : 22.0\n",
            "수식을 w로 미분한 값 : 24.0\n",
            "수식을 w로 미분한 값 : 26.0\n",
            "수식을 w로 미분한 값 : 28.0\n",
            "수식을 w로 미분한 값 : 30.0\n",
            "수식을 w로 미분한 값 : 32.0\n",
            "수식을 w로 미분한 값 : 34.0\n",
            "수식을 w로 미분한 값 : 36.0\n",
            "수식을 w로 미분한 값 : 38.0\n",
            "수식을 w로 미분한 값 : 40.0\n",
            "수식을 w로 미분한 값 : 42.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**torch.manual_seed()를 하는 이유**"
      ],
      "metadata": {
        "id": "HGiWzgd2ix0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.manual_seed()를 사용한 프로그램의 결과는 다른 컴퓨터에서 실행시켜도 동일한 결과를 낸다.\n",
        "#torch.manual_seed()는 난수 발생 순서와 값을 동일하게 보장해주는 특징을 갖고 있기 때문이다!"
      ],
      "metadata": {
        "id": "Ah3jrsJgiz_j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "zTEYhoPyjMaF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(3) #랜덤시드가 3\n",
        "print('랜덤 시드가 3일 때')\n",
        "for i in range(1,3):\n",
        "  print(torch.rand(1))\n",
        "#랜덤시드가 3일 때 난수 2개를 발생시켰더니 0.0043과 0.1056이 나옴  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20Za5EYdjM65",
        "outputId": "a3edfb1d-2b1b-4628-b543-1a30c547dfb8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시드가 3일 때\n",
            "tensor([0.0043])\n",
            "tensor([0.1056])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(5)\n",
        "print('랜덤 시드가 5일 때')\n",
        "for i in range(1,3):\n",
        "  print(torch.rand(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj7DhGPNkFBY",
        "outputId": "68b68b0a-0053-4c52-8961-672ce95523a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시드가 5일 때\n",
            "tensor([0.8303])\n",
            "tensor([0.1261])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#다시 랜덤 시드값을 처음에 한 것처럼 3으로 돌려보자! 그럼 어떻게 될까?\n",
        "torch.manual_seed(3)\n",
        "print('랜덤 시드가 3일 때')\n",
        "for i in range(1,3):\n",
        "  print(torch.rand(1))\n",
        "  #동일한 값 도출"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCxlTikNkbcL",
        "outputId": "e0df844e-f908-4f2a-f06a-91cf4bd8ca83"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 시드가 3일 때\n",
            "tensor([0.0043])\n",
            "tensor([0.1056])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tersor에는 requires_grab라는 속성이 있는데, requires+grab=True로 설정하면 자동 미분 기능이 적용된다.\n",
        "#이렇게 설정된 텐서에서 연산을 하면 계산 그래프가 생성됨. backward 함수를 호출하면 그래프로부터 자동으로 미분이 계산된다! "
      ],
      "metadata": {
        "id": "RTxIadTnlXf1"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}